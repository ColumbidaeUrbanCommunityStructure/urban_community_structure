---
title: "Extract required data from eBird"
output:  html_document
bibliography: ../ref.bib  
---


```{r}
source('../env.R')
```
# Objectives
Two objectives in this script:
1. Find all the checklists meeting the @Callaghan_2017 criteria with in our initial city selection polygons
2. Find all the Columbidae species that occur on those checklists.

# Requirements
Install sqllite locally.
Download full eBird data and sampling data.

# eBird Sampling Data

## Check eBird raw sampling data
@eBird2023 data can be downloaded here:
https://science.ebird.org/en/use-ebird-data/download-ebird-data-products

```{r}
EBIRD_SAMPLE_DATA_RAW = '/Users/james/Dropbox/PhD/eBird/ebd_sampling_relNov-2023/ebd_sampling_relNov-2023.txt'
Sys.setenv(EBIRD_SAMPLE_FILE = EBIRD_SAMPLE_DATA_RAW)
```

Read first 5 columns of raw ebird sampling data
```{bash}
head -6 ${EBIRD_SAMPLE_FILE}
```

# Find all eBird localities with valid checklists within our cities
Our ultimate aim is to find all checklists within our cities that match the filters defined by @Callaghan_2017, and store filtered data in cache file.

Our process for doing this is:
1. Using eBird sampling data; find all complete checklists; that are travelling, area, or stationary; and created between the years 2013 to 2023; store these as our first pass.
2. Extract all eBird unique localities from the first pass of checklists
3. Join those localities to our initial city selection vector, and keep any location that is within an urban polygon. This creates a mapping of eBird locality to city.
4. Store both the first pass of checklists and the locality to city mapping in sqlite.
5. Extract all checklists from sqlite that are recorded at an urban locality applying the filters defined by @Callaghan_2017

## First pass to find valid checklists
Read header of eBird sampling data file, and print with column index.
```{bash}
let INDEX=1
head -1 ${EBIRD_SAMPLE_FILE} | sed 's/\t/\n/g' | while read column_header; do 
    echo ${INDEX}: $column_header
    let INDEX=${INDEX}+1
done
```

First we will find all complete checklists between 2013 and 2023, that are one of the reqiured protocols (travelling, stationary, or area).
We will store this first pass at filtering checklists in a temp file:
```{r}
EBIRD_CHECKLIST_FIRST_PASS = filename(TMP_DIR, 'ebird_checklist_first_pass_cache.txt')
Sys.setenv(EBIRD_CHECKLIST_FIRST_PASS_FILE = EBIRD_CHECKLIST_FIRST_PASS)
```

```{bash}
echo ${EBIRD_CHECKLIST_FIRST_PASS_FILE}
```

Here we cut for the following eBird raw columns
13: LOCALITY ID
15: LATITUDE
16: LONGITUDE
17: OBSERVATION DATE
20: SAMPLING EVENT IDENTIFIER
21: PROTOCOL TYPE
24: DURATION MINUTES
25: EFFORT DISTANCE KM
28: ALL SPECIES REPORTED

and then filter such that
"ALL SPECIES REPORTED" is true ("1")
"PROTOCOL TYPE" IN (Stationary, Traveling, Area)
"OBSERVATION DATE" >= 2013

to collect a unique set of (LOCALITY ID, LATITUDE, LONGITUDE)

We use bash for streaming the file and then
1. `cut` the columns we want to use
2. `grep` to find all complete checklists (line ending with 1)
3. `grep` to check for required protocols
4. `grep` to check for years 2013 -> 2023

```{bash}
COLUMNS=13,15,16,17,20,21,24,25,28
echo -e "locality_id\tlat\tlong\tobs_date\tchecklist_id\tprotocol\tduration\teffort_km\tcomplete" > ${EBIRD_CHECKLIST_FIRST_PASS_FILE} 
cat ${EBIRD_RAW_FILE} | cut -f${COLUMNS} | grep 1$ | grep -E "Traveling|Area|Stationary" | grep -E "\t20(1[3-9])|(2[0-3])-[0-1]" >> ${EBIRD_CHECKLIST_FIRST_PASS_FILE}
```

## Get all localities from valid checklists
Now we can get a unique list of localities from our first pass.
```{r}
EBIRD_ALL_LOCALITIES = filename(TMP_DIR, 'ebird_all_localities.txt')
Sys.setenv(EBIRD_ALL_LOCALITIES_FILE = EBIRD_ALL_LOCALITIES)
```

```{bash}
cat ${EBIRD_CHECKLIST_FIRST_PASS_FILE} | cut -f1,2,3 |  awk '!a[$0]++' >> ${EBIRD_ALL_LOCALITIES_FILE}
```

```{r}
all_ebird_locations = read_tsv(EBIRD_ALL_LOCALITIES)
head(all_ebird_locations)
```

## Find all urban localities using initial city selection
Read in our initial city vectors, we will join these to our checklists
```{r}
initial_city_selection = read_sf(filename(mkdir(GEO_WORKING_OUTPUT_DIR, 'cities'), 'initial_selection.shp'))
```

Turn our ebird locations into actual points
```{r}
all_ebird_locations_sf <- st_as_sf(all_ebird_locations, coords = c("long", "lat"))
st_crs(all_ebird_locations_sf) <- st_crs(initial_city_selection)

write_sf(all_ebird_locations_sf, filename(mkdir(GEO_WORKING_OUTPUT_DIR, 'ebird'), 'all_locations.shp'))
```

Join the eBird locations onto the city vectors, giving each location a city and discarding all other locations
```{r}
sf::sf_use_s2(FALSE)

localities_in_cities <- 
  st_join(all_ebird_locations_sf, initial_city_selection) %>%  # spatial join to get intersection of points and poly
  filter(!is.na(city_id))

head(localities_in_cities)
```

```{r}
localities_in_cities[localities_in_cities$locality_id == 'L6081908',] # Manchester
localities_in_cities[localities_in_cities$locality_id == 'L13024221',] # Bogota
```

```{r}
nrow(localities_in_cities)
```

Store urban locality to city mapping IDs in file.
```{r}
EBIRD_LOCALITY_TO_CITY = filename(EBIRD_WORKING_OUTPUT_DIR, 'locality_to_city.txt')
write_csv(data.frame(
  locality_id = localities_in_cities$locality_id, 
  city_id = localities_in_cities$city_id,
  city_name= localities_in_cities$city_name
  ), EBIRD_LOCALITY_TO_CITY)
```

## Store data into SQLLite
```{r}
Sys.setenv(EBIRD_LOCALITY_TO_CITY_FILE = EBIRD_LOCALITY_TO_CITY)
```

```{r}
CHECKLIST_DATABASE_FILE = filename(TMP_DIR, 'checklists.sqllite.db')
Sys.setenv(CHECKLIST_DB = CHECKLIST_DATABASE_FILE)
```

```{bash}
sqlite3 ${CHECKLIST_DB} "CREATE TABLE checklists (locality_id NVARCHAR(12), lat FLOAT, long FLOAT, obs_date DATE, checklist_id NVARCHAR(12), protocol NVARCHAR(12), duration INTEGER, effort_km INTEGER, complete TINYINT);"
```

```{bash}
echo -e ".separator \\t\n.import ${EBIRD_CHECKLIST_FIRST_PASS_FILE} checklists" > /tmp/import_command.sqlite
sqlite3 ${CHECKLIST_DB} < /tmp/import_command.sqlite
```

```{bash}
sqlite3 ${CHECKLIST_DB} "CREATE TABLE locality_to_city (locality_id NVARCHAR(12), city_id INT, city_name NVARCHAR(100));"
```

```{bash}
sqlite3 ${CHECKLIST_DB} ".import --csv ${EBIRD_LOCALITY_TO_CITY_FILE} locality_to_city"
```

## Export urban checklists from sqlite
Finally we can filter out first pass of checklists to only urban checklists, and checklists satisfy all of the criteria of @Callaghan_2017.

```{r}
EBIRD_LOCALITY_TO_CITY = filename(EBIRD_WORKING_OUTPUT_DIR, "urban_checklists.csv")
Sys.setenv(EBIRD_URBAN_CHECKLISTS_FILE = EBIRD_LOCALITY_TO_CITY)
```

Where we apply the filter such that:
1. duration >= 5 AND duration <= 240
2. effort_km = '' OR (effort_km >= 0 AND effort_km <= 10)
```{bash}
echo -e ".mode csv\n.headers on\nSELECT checklist_id, locality_id, city_id, city_name, duration, obs_date FROM checklists JOIN locality_to_city USING (locality_id) WHERE duration >= 5 AND duration <= 240 AND (effort_km = '' OR (effort_km >= 0 AND effort_km <= 10))" > /tmp/export_command.sqlite
sqlite3 ${CHECKLIST_DB} < /tmp/export_command.sqlite > ${EBIRD_URBAN_CHECKLISTS_FILE}
```

# Find all Columbidae records
Here we want to find all Columbidae records from eBird that are present on our extracted checklists.

The process we follow to complete this is:
1. 
2.
3.
4.

## Check eBird raw data
@eBird2023 data can be downloaded here:
https://science.ebird.org/en/use-ebird-data/download-ebird-data-products

```{r}
EBIRD_DATA_RAW = '/Users/james/Dropbox/PhD/eBird/ebd_relNov-2023/ebd_relNov-2023.txt'
Sys.setenv(EBIRD_FILE = EBIRD_DATA_RAW)
```

Read first 5 columns of raw ebird sampling data
```{bash}
head -6 ${EBIRD_FILE}
```

## Extract a first pass of required observations
Here we get all pigeon records on complete checklists of the required protocol within the years 2013 to 2023

Read header of eBird sampling data file, and print with column index.
```{bash}
let INDEX=1
head -1 ${EBIRD_FILE} | sed 's/\t/\n/g' | while read column_header; do 
    echo ${INDEX}: $column_header
    let INDEX=${INDEX}+1
done
```

```{r}
EBIRD_OBSERVATIONS_FIRST_PASS = filename(TMP_DIR, 'ebird_obs_first_pass_cache.txt')
Sys.setenv(EBIRD_OBSERVATIONS_FIRST_PASS_FILE = EBIRD_OBSERVATIONS_FIRST_PASS)
```

3: TAXONOMIC ORDER
6: COMMON NAME
7: SCIENTIFIC NAME
11: OBSERVATION COUNT
12: BREEDING CODE
31: OBSERVATION DATE
34: SAMPLING EVENT IDENTIFIER
35: PROTOCOL TYPE
41: NUMBER OBSERVERS
42: ALL SPECIES REPORTED
43: GROUP IDENTIFIER

WIP
```{bash}
COLUMNS=
echo -e "" > ${EBIRD_OBSERVATIONS_FIRST_PASS_FILE} 
cat ${EBIRD_RAW_FILE} | cut -f${COLUMNS} | grep 1$ | grep -E "Traveling|Area|Stationary" | grep -E "\t20(1[3-9])|(2[0-3])-[0-1]" >> ${EBIRD_OBSERVATIONS_FIRST_PASS_FILE}
```


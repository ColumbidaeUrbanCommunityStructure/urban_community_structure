head(traits)
resolve = read_resolve()
head(resolve)
test_required_values = function(name, df) {
cat(paste(
test_value_wilcox(paste(name, 'MNTD'), df$mntd_normalised),
test_value_wilcox(paste(name, 'Beak Gape FDiv'), df$gape_width_fdiv_normalised),
test_value_wilcox(paste(name, 'HWI FDiv'), df$handwing_index_fdiv_normalised),
test_value_wilcox(paste(name, 'Mass FDiv'), df$mass_fdiv_normalised),
nrow(df),
sep = "\n"))
}
test_required_values('Global', community_data_with_realm)
unique(community_data_with_realm$core_realm)
test_required_values('Nearctic', community_data_with_realm[community_data_with_realm$core_realm == 'Nearctic',])
test_required_values('Neotropic', community_data_with_realm[community_data_with_realm$core_realm == 'Neotropic',])
test_required_values('Palearctic', community_data_with_realm[community_data_with_realm$core_realm == 'Palearctic',])
test_required_values('Afrotropic', community_data_with_realm[community_data_with_realm$core_realm == 'Afrotropic',])
test_required_values('Indomalayan', community_data_with_realm[community_data_with_realm$core_realm == 'Indomalayan',])
test_required_values('Australasia', community_data_with_realm[community_data_with_realm$core_realm == 'Australasia',])
communities = read_csv(filename(COMMUNITY_OUTPUT_DIR, 'communities_for_analysis.csv'))
city_introduced_species = communities %>% group_by(city_id) %>% summarise(number_of_species = n()) %>% left_join(
communities %>% group_by(city_id) %>% filter(origin == 'Introduced') %>% summarise(number_of_introduced_species = n())
) %>% replace_na(list(number_of_introduced_species = 0))
community_data_with_introductions = left_join(community_data, city_introduced_species)
community_data_with_introductions$has_introduced_species = community_data_with_introductions$number_of_introduced_species > 0
community_data_with_introductions
community_data_with_introductions[,c('mntd_normalised', 'has_introduced_species')]
community_data_with_introductions %>% group_by(has_introduced_species) %>% summarise(
mean_mntd_normalised = mean(mntd_normalised, na.rm = T),
sd_mntd_normalised = sd(mntd_normalised, na.rm = T),
mean_mass_fdiv_normalised = mean(mass_fdiv_normalised, na.rm = T),
sd_mass_fdiv_normalised = sd(mass_fdiv_normalised, na.rm = T),
mean_gape_width_fdiv_normalised = mean(gape_width_fdiv_normalised, na.rm = T),
sd_gape_width_fdiv_normalised = sd(gape_width_fdiv_normalised, na.rm = T),
mean_handwing_index_fdiv_normalised = mean(handwing_index_fdiv_normalised, na.rm = T),
sd_handwing_index_fdiv_normalised = sd(handwing_index_fdiv_normalised, na.rm = T)
)
ggplot(community_data_with_introductions, aes(x = has_introduced_species, y = mntd_normalised)) + geom_boxplot()
wilcox.test(mntd_normalised ~ has_introduced_species, community_data_with_introductions)
wilcox.test(mntd_normalised ~ has_introduced_species, community_data_with_introductions, na.rm = T)
wilcox.test(mntd_normalised ~ has_introduced_species, community_data_with_introductions, rm.na = T)
wilcox.test(mntd_normalised ~ has_introduced_species, community_data_with_introductions, na.action = 'remove')
wilcox.test(mntd_normalised ~ has_introduced_species, community_data_with_introductions, na.action = 'na.omit')
wilcox.test(mntd_normalised ~ has_introduced_species, community_data_with_introductions, na.action = 'na.omit')
ggplot(community_data_with_introductions, aes(x = has_introduced_species, y = mass_fdiv_normalised)) + geom_boxplot()
wilcox.test(mass_fdiv_normalised ~ has_introduced_species, community_data_with_introductions)
wilcox.test(mass_fdiv_normalised ~ has_introduced_species, community_data_with_introductions, na.action = 'na.omit')
ggplot(community_data_with_introductions, aes(x = has_introduced_species, y = gape_width_fdiv_normalised)) + geom_boxplot()
wilcox.test(gape_width_fdiv_normalised ~ has_introduced_species, community_data_with_introductions)
wilcox.test(gape_width_fdiv_normalised ~ has_introduced_species, community_data_with_introductions, na.action = 'na.omit')
ggplot(community_data_with_introductions, aes(x = has_introduced_species, y = handwing_index_fdiv_normalised)) + geom_boxplot()
wilcox.test(handwing_index_fdiv_normalised ~ has_introduced_species, community_data_with_introductions)
wilcox.test(handwing_index_fdiv_normalised ~ has_introduced_species, community_data_with_introductions, na.action = 'na.omit')
geography = read_csv(filename(CITY_DATA_OUTPUT_DIR, 'geography.csv'))
names(geography)
analysis_data = community_data_with_realm[,c('city_id', 'mntd_normalised', 'mass_fdiv_normalised', 'gape_width_fdiv_normalised', 'handwing_index_fdiv_normalised', 'core_realm')] %>%
left_join(city_points[,c('city_id', 'latitude', 'longitude')]) %>%
left_join(community_data_with_introductions[,c('city_id', 'has_introduced_species')]) %>%
left_join(geography)
analysis_data$abs_latitude = abs(analysis_data$latitude)
analysis_data$core_realm = as.factor(analysis_data$core_realm)
analysis_data$has_introduced_species = as.factor(analysis_data$has_introduced_species)
model_data = function(df, dependant_var) {
df[,c(dependant_var, 'core_realm', 'abs_latitude', 'latitude', 'longitude', 'has_introduced_species', 'city_avg_ndvi', 'city_avg_elevation', 'city_avg_temp', 'city_avg_min_monthly_temp', 'city_avg_max_monthly_temp', 'city_avg_monthly_temp', 'city_avg_rainfall', 'city_avg_max_monthly_rainfall', 'city_avg_min_monthly_rainfall', 'city_avg_soil_moisture', 'city_max_elev', 'city_min_elev', 'city_elev_range', 'region_20km_avg_ndvi', 'region_20km_avg_elevation', 'region_20km_avg_soil_moisture', 'region_20km_max_elev', 'region_20km_min_elev', 'region_20km_elev_range', 'region_50km_avg_ndvi', 'region_50km_avg_elevation', 'region_50km_avg_soil_moisture', 'region_50km_max_elev', 'region_50km_min_elev', 'region_50km_elev_range')]
}
model_data(analysis_data, 'mntd_normalised')
geom_normalised_histogram = function(name, gg, legend.position = "right") {
gg +
geom_histogram(aes(fill = core_realm), binwidth = 0.1, position = "dodge") +
geom_vline(aes(xintercept = 0.5), color = "#000000", size = 0.4) +
geom_vline(aes(xintercept = 0), color = "#000000", size = 0.2, linetype = "dashed") +
geom_vline(aes(xintercept = 1), color = "#000000", size = 0.2, linetype = "dashed") +
ylab("Number of cities") + xlab("Normalised Response") + ylim(c(0, 70)) +
labs(title = name, fill = 'Realm') +
theme_bw() +
theme(legend.position=legend.position)
}
geom_map = function(map_sf, title) {
norm_mntd_analysis_geo = ggplot() +
geom_sf(data = world_map, aes(geometry = geometry)) +
map_sf +
normalised_colours_scale +
labs(title = title, colour = 'Normalised\nResponse')
}
# Taken from MuMIN package
# https://rdrr.io/cran/MuMIn/src/R/averaging.R
# https://rdrr.io/cran/MuMIn/src/R/model.avg.R
.coefarr.avg <-
function(cfarr, weight, revised.var, full, alpha) {
weight <- weight / sum(weight)
nCoef <- dim(cfarr)[3L]
if(full) {
nas <- is.na(cfarr[, 1L, ]) & is.na(cfarr[, 2L, ])
cfarr[, 1L, ][nas] <- cfarr[, 2L, ][nas] <- 0
#cfarr[, 1L:2L, ][is.na(cfarr[, 1L:2L, ])] <- 0
if(!all(is.na(cfarr[, 3L, ])))
cfarr[ ,3L, ][is.na(cfarr[ , 3L, ])] <- Inf
}
avgcoef <- array(dim = c(nCoef, 5L),
dimnames = list(dimnames(cfarr)[[3L]], c("Estimate",
"Std. Error", "Adjusted SE", "Lower CI", "Upper CI")))
for(i in seq_len(nCoef))
avgcoef[i, ] <- par.avg(cfarr[, 1L, i], cfarr[, 2L, i], weight,
df = cfarr[, 3L, i], alpha = alpha, revised.var = revised.var)
avgcoef[is.nan(avgcoef)] <- NA
return(avgcoef)
}
.makecoefmat <- function(cf) {
no.ase <- all(is.na(cf[, 3L]))
z <- abs(cf[, 1L] / cf[, if(no.ase) 2L else 3L])
pval <- 2 * pnorm(z, lower.tail = FALSE)
cbind(cf[, if(no.ase) 1L:2L else 1L:3L, drop = FALSE],
`z value` = z, `Pr(>|z|)` = zapsmall(pval))
}
# Generate model selections using lmer, dredge, and model.avg
# `forumla` : a two-sided linear formula object describing both the fixed-effects and random-effects part of the model
# `data` : the data frame containing the variables from the formula
# `aic_delta` : the AIC delta to use for selecting models in model average
model_average <- function(formula, data, aic_delta) {
model <- lm(
formula,
data=data
)
dredge_result <- dredge(model)
summary(model.avg(dredge_result, subset = delta < aic_delta))
}
# Create a summary data frame containing the selected variables from a model
# `model_sum` : The model summary output from `model_average`
model_summary <- function(response_var, model_sum) {
.column_name <- function(postfix) {
postfix
}
# just return the estimate and p value
weight <- model_sum$msTable[, 5L]
coefmat.full <- as.data.frame(.makecoefmat(.coefarr.avg(model_sum$coefArray, weight,
attr(model_sum, "revised.var"), TRUE, 0.05)))
coefmat.subset <-
as.data.frame(.makecoefmat(.coefarr.avg(model_sum$coefArray, weight,
attr(model_sum, "revised.var"), FALSE, 0.05)))
coefmat.subset <- coefmat.subset[-c(1), c(1, 2, 5)]
names(coefmat.subset) <- c(.column_name("estimate"), .column_name("error"), .column_name("p"))
coefmat.subset <- tibble::rownames_to_column(coefmat.subset, "explanatory")
coefmat.subset$model = 'subset'
coefmat.full <- coefmat.full[-c(1), c(1, 2, 5)]
names(coefmat.full) <- c(.column_name("estimate"), .column_name("error"), .column_name("p"))
coefmat.full <- tibble::rownames_to_column(coefmat.full, "explanatory")
coefmat.full$model = 'full'
rbind(coefmat.full, coefmat.subset)
}
norm_mntd_analysis_plot = geom_normalised_histogram(
'MNTD',
ggplot(analysis_data, aes(mntd_normalised))
)
norm_mntd_analysis_plot
norm_mntd_analysis_geo = geom_map(geom_sf(data = analysis_data, aes(color = mntd_normalised, geometry = geometry)), 'MNTD')
norm_mntd_analysis_geo
ggsave(filename(FIGURES_OUTPUT_DIR, 'normalised_mntd_using_abundance.jpg'), width = 2500, height=1100, units = 'px')
norm_mntd_analysis_data = model_data(analysis_data[!is.na(analysis_data$mntd_normalised),], 'mntd_normalised')
norm_mntd_analysis_result <- model_average(mntd_normalised ~ ., norm_mntd_analysis_data, 4)
norm_mntd_analysis_data = model_data(analysis_data[!is.na(analysis_data$mntd_normalised),], 'mntd_normalised')
VSURF(x = norm_mntd_analysis_data[,-1], y = norm_mntd_analysis_data[,1])
install.packages("VSURF")
library(VSURF)
norm_mntd_analysis_data = model_data(analysis_data[!is.na(analysis_data$mntd_normalised),], 'mntd_normalised')
VSURF(x = norm_mntd_analysis_data[,-1], y = norm_mntd_analysis_data[,1])
norm_mntd_analysis_data[,-1]
norm_mntd_analysis_data[,1]
VSURF(x = norm_mntd_analysis_data[,-1], y = norm_mntd_analysis_data$mntd_normalised)
norm_mntd_analysis_data = model_data(analysis_data[!is.na(analysis_data$mntd_normalised),], 'mntd_normalised')
norm_mntd_analysis_predictors = norm_mntd_analysis_data[,-1]
norm_mntd_analysis_interp = VSURF(x = norm_mntd_analysis_predictors, y = norm_mntd_analysis_data$mntd_normalised)
names(norm_mntd_analysis_predictors[,norm_mntd_analysis_interp$varselect.interp])
norm_mntd_analysis_result <- model_average(mntd_normalised ~ norm_mntd_analysis_predictors + city_avg_max_monthly_temp + longitude + core_realm + city_avg_temp + latitude + abs_latitude + city_avg_min_monthly_temp, norm_mntd_analysis_data, 4)
norm_mntd_analysis_result <- model_average(mntd_normalised ~ city_avg_monthly_temp + city_avg_max_monthly_temp + longitude + core_realm + city_avg_temp + latitude + abs_latitude + city_avg_min_monthly_temp, norm_mntd_analysis_data, 4)
model_summary(norm_mntd_analysis_result)
norm_mntd_analysis_result
model_summary(norm_mntd_analysis_result)
# Taken from MuMIN package
# https://rdrr.io/cran/MuMIn/src/R/averaging.R
# https://rdrr.io/cran/MuMIn/src/R/model.avg.R
.coefarr.avg <-
function(cfarr, weight, revised.var, full, alpha) {
weight <- weight / sum(weight)
nCoef <- dim(cfarr)[3L]
if(full) {
nas <- is.na(cfarr[, 1L, ]) & is.na(cfarr[, 2L, ])
cfarr[, 1L, ][nas] <- cfarr[, 2L, ][nas] <- 0
#cfarr[, 1L:2L, ][is.na(cfarr[, 1L:2L, ])] <- 0
if(!all(is.na(cfarr[, 3L, ])))
cfarr[ ,3L, ][is.na(cfarr[ , 3L, ])] <- Inf
}
avgcoef <- array(dim = c(nCoef, 5L),
dimnames = list(dimnames(cfarr)[[3L]], c("Estimate",
"Std. Error", "Adjusted SE", "Lower CI", "Upper CI")))
for(i in seq_len(nCoef))
avgcoef[i, ] <- par.avg(cfarr[, 1L, i], cfarr[, 2L, i], weight,
df = cfarr[, 3L, i], alpha = alpha, revised.var = revised.var)
avgcoef[is.nan(avgcoef)] <- NA
return(avgcoef)
}
.makecoefmat <- function(cf) {
no.ase <- all(is.na(cf[, 3L]))
z <- abs(cf[, 1L] / cf[, if(no.ase) 2L else 3L])
pval <- 2 * pnorm(z, lower.tail = FALSE)
cbind(cf[, if(no.ase) 1L:2L else 1L:3L, drop = FALSE],
`z value` = z, `Pr(>|z|)` = zapsmall(pval))
}
# Generate model selections using lmer, dredge, and model.avg
# `forumla` : a two-sided linear formula object describing both the fixed-effects and random-effects part of the model
# `data` : the data frame containing the variables from the formula
# `aic_delta` : the AIC delta to use for selecting models in model average
model_average <- function(formula, data, aic_delta) {
model <- lm(
formula,
data=data
)
dredge_result <- dredge(model)
summary(model.avg(dredge_result, subset = delta < aic_delta))
}
# Create a summary data frame containing the selected variables from a model
# `model_sum` : The model summary output from `model_average`
model_summary <- function(model_sum) {
.column_name <- function(postfix) {
postfix
}
# just return the estimate and p value
weight <- model_sum$msTable[, 5L]
coefmat.full <- as.data.frame(.makecoefmat(.coefarr.avg(model_sum$coefArray, weight,
attr(model_sum, "revised.var"), TRUE, 0.05)))
coefmat.subset <-
as.data.frame(.makecoefmat(.coefarr.avg(model_sum$coefArray, weight,
attr(model_sum, "revised.var"), FALSE, 0.05)))
coefmat.subset <- coefmat.subset[-c(1), c(1, 2, 5)]
names(coefmat.subset) <- c(.column_name("estimate"), .column_name("error"), .column_name("p"))
coefmat.subset <- tibble::rownames_to_column(coefmat.subset, "explanatory")
coefmat.subset$model = 'subset'
coefmat.full <- coefmat.full[-c(1), c(1, 2, 5)]
names(coefmat.full) <- c(.column_name("estimate"), .column_name("error"), .column_name("p"))
coefmat.full <- tibble::rownames_to_column(coefmat.full, "explanatory")
coefmat.full$model = 'full'
rbind(coefmat.full, coefmat.subset)
}
norm_mntd_analysis_result <- model_average(mntd_normalised ~ city_avg_monthly_temp + city_avg_max_monthly_temp + longitude + core_realm + city_avg_temp + latitude + abs_latitude + city_avg_min_monthly_temp, norm_mntd_analysis_data, 4)
model_summary(norm_mntd_analysis_result)
community_data_with_realm
communities
communities %>% left_join(city_to_realm)
source('../env.R')
communities %>% left_join(city_to_realm)
communities %>% left_join(city_to_realm) %>% select(jetz_species_name, core_realm)
communities %>%
left_join(city_to_realm) %>%
select(jetz_species_name, core_realm) %>%
mutate(family = gsub( " .*$", "", jetz_species_name))
detach("package:VSURF", unload = TRUE)
communities %>%
left_join(city_to_realm) %>%
dplyr::select(jetz_species_name, core_realm) %>%
mutate(family = gsub( " .*$", "", jetz_species_name))
communities %>%
left_join(city_to_realm) %>%
dplyr::select(jetz_species_name, core_realm) %>%
mutate(family = gsub( "_.*$", "", jetz_species_name))
communities %>%
left_join(city_to_realm) %>%
mutate(family = gsub( "_.*$", "", jetz_species_name)) %>%
dplyr::select(family, core_realm) %>%
distinct()
communities %>%
left_join(city_to_realm) %>%
mutate(family = gsub( "_.*$", "", jetz_species_name)) %>%
dplyr::select(family, core_realm) %>%
distinct() %>%
arrange(core_realm)
communities %>%
left_join(city_to_realm) %>%
mutate(family = gsub( "_.*$", "", jetz_species_name)) %>%
dplyr::select(family, core_realm) %>%
distinct() %>%
arrange(core_realm)
source('../env.R')
BiocManager::install("YuLab-SMU/treedataverse")
install.packages("BiocManager")
BiocManager::install("YuLab-SMU/treedataverse")
library(treedataverse) # BiocManager::install("YuLab-SMU/treedataverse")
BiocManager::install("remotes")
library(treedataverse) # BiocManager::install("YuLab-SMU/treedataverse")
BiocManager::install("YuLab-SMU/treedataverse")
source('../env.R')
raw_data = read_csv(filename(COMMUNITY_OUTPUT_DIR, 'jetz_all_recorded_species_with_spatial_data.csv'))
raw_data_trimmed_to_accepted_cities = raw_data[raw_data$percentage_total_city_area_surveyed > 10,]
length(unique(raw_data_trimmed_to_accepted_cities$city_id))
pools = raw_data_trimmed_to_accepted_cities[!is.na(raw_data_trimmed_to_accepted_cities$seasonal),]
pools$present_urban_high = pools$percentage_surveyed_area > 40
pools$present_urban_med = pools$percentage_surveyed_area > 15
pools$present_urban_low = pools$percentage_surveyed_area > 3.5
head(pools)
distances = read_csv(filename(GEO_WORKING_OUTPUT_DIR, 'distance_to_range_edge.csv'))
nrow(pools)
nrow(pools %>% left_join(distances))
pools %>% left_join(distances) %>% filter(distance_to_northern_edge == Inf)
write_csv(pools %>%
left_join(distances) %>%
mutate(distance_to_northern_edge_km = distance_to_northern_edge / 1000, distance_to_southern_edge_km = distance_to_southern_edge / 1000) %>%
dplyr::select(
city_id,
city_name,
jetz_species_name,
seasonal,
presence,
origin,
distance_to_northern_edge_km,
distance_to_southern_edge_km,
present_urban_high,
present_urban_med,
present_urban_low,
percentage_surveyed_area
) %>% dplyr::rename(relative_abundance_proxy='percentage_surveyed_area'), filename(COMMUNITY_OUTPUT_DIR, 'communities_for_analysis.csv'))
city_data = pools %>%
dplyr::select(
city_id,
city_name,
total_city_checklists,
total_city_locations,
total_city_effort,
total_city_area_m2,
percentage_total_city_area_surveyed
) %>%
distinct()
write_csv(city_data, filename(CITY_DATA_OUTPUT_DIR, 'city_effort.csv'))
initial_city_selection = st_read(filename(mkdir(GEO_WORKING_OUTPUT_DIR, 'cities'), 'initial_selection.shp'))
final_city_selection = initial_city_selection[initial_city_selection$city_id %in% city_data$city_id,] %>%
left_join(city_data) %>%
dplyr::select(!c('total_city_area_m2')) %>%
mutate(across(where(is.numeric), as.integer))
write_sf(final_city_selection, filename(CITY_DATA_OUTPUT_DIR, 'city_selection.shp'))
world_map = read_country_boundaries()
ggplot() +
geom_sf(data = world_map, aes(geometry = geometry)) +
geom_sf(data = final_city_selection, aes(geometry = geometry, colour = percentage_total_city_area_surveyed)) +
theme(legend.position="bottom") + scale_colour_gradient2(
low = "darkgreen",
mid = "yellow",
high = "red",
midpoint = 3,
space = "Lab",
na.value = "grey50",
guide = "colourbar",
aesthetics = "colour",
)
abundance_data = read_csv(filename(EBIRD_WORKING_OUTPUT_DIR, 'ebird_trends_abundance_test_data.csv'))
head(abundance_data)
taxonomic_mapping = read_csv(filename(TAXONOMY_OUTPUT_DIR, 'taxonomy_mapping.csv'))
test_species = unique(abundance_data$species)
test_species_mapping = unique(taxonomic_mapping[taxonomic_mapping$ebird_species_name %in% test_species, c('ebird_species_name', 'jetz_species_name')])
test_species_mapping[order(test_species_mapping$ebird_species_name),] %>% arrange(jetz_species_name)
abundance_data_jetz = abundance_data %>% left_join(test_species_mapping, by=c('species' = 'ebird_species_name')) %>% dplyr::select(-c('species'))
abundance_data_jetz
abundance_data_jetz$max_mean_abundance = apply(abundance_data_jetz[,c('mean_breeding', 'mean_nonbreeding', 'mean_resident')], 1, max, na.rm = T)
abundance_data_jetz$max_mean_abundance[abundance_data_jetz$max_mean_abundance == -Inf] = NA
analytical_pools = read_csv(filename(COMMUNITY_OUTPUT_DIR, 'communities_for_analysis.csv'))
comparison_data = inner_join(analytical_pools, abundance_data_jetz[,c('city_id', 'jetz_species_name', 'max_mean_abundance')])
comparison_data
comparison_data$present_urban_never = !comparison_data$present_urban_low & !comparison_data$present_urban_med & !comparison_data$present_urban_high
comparison_data %>%
dplyr::select(city_id, jetz_species_name, max_mean_abundance, present_urban_high, present_urban_med, present_urban_low, present_urban_never) %>%
filter(sqrt(max_mean_abundance) < 5) %>%
pivot_longer(cols = starts_with('present_urban'), names_to = 'urban_pool') %>%
mutate(urban_pool = factor(urban_pool, levels=c('present_urban_never', 'present_urban_low', 'present_urban_med', 'present_urban_high'), labels=c('Always Absent', 'Low', 'Medium', 'High'))) %>%
filter(value) %>%
ggplot(aes(x = urban_pool, y = max_mean_abundance)) +
geom_boxplot() +
xlab('Threshold') +
ylab('Mean abundance across cities') +
labs(title = 'Mean Species Urban Abundance at each Threshold', subtitle='eBird Status & Trends abundance data') +
theme_bw() +
theme(legend.position = "none")
ggsave(filename(FIGURES_OUTPUT_DIR, 'thresholds_to_ebird_trends_and_status_abundance_data.jpg'))
comparison_data %>%
ggplot(aes(x = relative_abundance_proxy, y = sqrt(max_mean_abundance))) +
geom_point() +
xlab('Abundance Proxy') +
ylab('Mean abundance across cities (sqrt)') +
labs(title = 'Abundance proxy vs eBird relative abundance estimate', subtitle='eBird Status & Trends abundance data') +
theme_bw() +
theme(legend.position = "none")
ggsave(filename(FIGURES_OUTPUT_DIR, 'abundance_proxy_to_ebird_trends_and_status_abundance_data.jpg'))
raw_data
raw_data = read_csv(filename(COMMUNITY_OUTPUT_DIR, 'jetz_all_recorded_species_with_spatial_data.csv'))
raw_data_trimmed_to_accepted_cities = raw_data[raw_data$percentage_total_city_area_surveyed > 10 && raw_data$total_city_locations > 10,]
raw_data = read_csv(filename(COMMUNITY_OUTPUT_DIR, 'jetz_all_recorded_species_with_spatial_data.csv'))
raw_data_trimmed_to_accepted_cities = raw_data[raw_data$percentage_total_city_area_surveyed > 10 & raw_data$total_city_locations > 10,]
length(unique(raw_data_trimmed_to_accepted_cities$city_id))
pools = raw_data_trimmed_to_accepted_cities[!is.na(raw_data_trimmed_to_accepted_cities$seasonal),]
pools$present_urban_high = pools$percentage_surveyed_area > 40
pools$present_urban_med = pools$percentage_surveyed_area > 15
pools$present_urban_low = pools$percentage_surveyed_area > 3.5
head(pools)
source('../env.R')
raw_data = read_csv(filename(COMMUNITY_OUTPUT_DIR, 'jetz_all_recorded_species_with_spatial_data.csv'))
raw_data_trimmed_to_accepted_cities = raw_data[raw_data$percentage_total_city_area_surveyed > 10 & raw_data$total_city_locations > 10,]
length(unique(raw_data_trimmed_to_accepted_cities$city_id))
pools = raw_data_trimmed_to_accepted_cities[!is.na(raw_data_trimmed_to_accepted_cities$seasonal),]
pools$present_urban_high = pools$percentage_surveyed_area > 40
pools$present_urban_med = pools$percentage_surveyed_area > 15
pools$present_urban_low = pools$percentage_surveyed_area > 3.5
head(pools)
distances = read_csv(filename(GEO_WORKING_OUTPUT_DIR, 'distance_to_range_edge.csv'))
nrow(pools)
nrow(pools %>% left_join(distances))
pools %>% left_join(distances) %>% filter(distance_to_northern_edge == Inf)
write_csv(pools %>%
left_join(distances) %>%
mutate(distance_to_northern_edge_km = distance_to_northern_edge / 1000, distance_to_southern_edge_km = distance_to_southern_edge / 1000) %>%
dplyr::select(
city_id,
city_name,
jetz_species_name,
seasonal,
presence,
origin,
distance_to_northern_edge_km,
distance_to_southern_edge_km,
present_urban_high,
present_urban_med,
present_urban_low,
percentage_surveyed_area
) %>% dplyr::rename(relative_abundance_proxy='percentage_surveyed_area'), filename(COMMUNITY_OUTPUT_DIR, 'communities_for_analysis.csv'))
city_data = pools %>%
dplyr::select(
city_id,
city_name,
total_city_checklists,
total_city_locations,
total_city_effort,
total_city_area_m2,
percentage_total_city_area_surveyed
) %>%
distinct()
write_csv(city_data, filename(CITY_DATA_OUTPUT_DIR, 'city_effort.csv'))
initial_city_selection = st_read(filename(mkdir(GEO_WORKING_OUTPUT_DIR, 'cities'), 'initial_selection.shp'))
final_city_selection = initial_city_selection[initial_city_selection$city_id %in% city_data$city_id,] %>%
left_join(city_data) %>%
dplyr::select(!c('total_city_area_m2')) %>%
mutate(across(where(is.numeric), as.integer))
write_sf(final_city_selection, filename(CITY_DATA_OUTPUT_DIR, 'city_selection.shp'))
world_map = read_country_boundaries()
ggplot() +
geom_sf(data = world_map, aes(geometry = geometry)) +
geom_sf(data = final_city_selection, aes(geometry = geometry, colour = percentage_total_city_area_surveyed)) +
theme(legend.position="bottom") + scale_colour_gradient2(
low = "darkgreen",
mid = "yellow",
high = "red",
midpoint = 3,
space = "Lab",
na.value = "grey50",
guide = "colourbar",
aesthetics = "colour",
)
abundance_data = read_csv(filename(EBIRD_WORKING_OUTPUT_DIR, 'ebird_trends_abundance_test_data.csv'))
head(abundance_data)
taxonomic_mapping = read_csv(filename(TAXONOMY_OUTPUT_DIR, 'taxonomy_mapping.csv'))
test_species = unique(abundance_data$species)
test_species_mapping = unique(taxonomic_mapping[taxonomic_mapping$ebird_species_name %in% test_species, c('ebird_species_name', 'jetz_species_name')])
test_species_mapping[order(test_species_mapping$ebird_species_name),] %>% arrange(jetz_species_name)
abundance_data_jetz = abundance_data %>% left_join(test_species_mapping, by=c('species' = 'ebird_species_name')) %>% dplyr::select(-c('species'))
abundance_data_jetz
abundance_data_jetz$max_mean_abundance = apply(abundance_data_jetz[,c('mean_breeding', 'mean_nonbreeding', 'mean_resident')], 1, max, na.rm = T)
abundance_data_jetz$max_mean_abundance[abundance_data_jetz$max_mean_abundance == -Inf] = NA
analytical_pools = read_csv(filename(COMMUNITY_OUTPUT_DIR, 'communities_for_analysis.csv'))
comparison_data = inner_join(analytical_pools, abundance_data_jetz[,c('city_id', 'jetz_species_name', 'max_mean_abundance')])
comparison_data
comparison_data$present_urban_never = !comparison_data$present_urban_low & !comparison_data$present_urban_med & !comparison_data$present_urban_high
comparison_data %>%
dplyr::select(city_id, jetz_species_name, max_mean_abundance, present_urban_high, present_urban_med, present_urban_low, present_urban_never) %>%
filter(sqrt(max_mean_abundance) < 5) %>%
pivot_longer(cols = starts_with('present_urban'), names_to = 'urban_pool') %>%
mutate(urban_pool = factor(urban_pool, levels=c('present_urban_never', 'present_urban_low', 'present_urban_med', 'present_urban_high'), labels=c('Always Absent', 'Low', 'Medium', 'High'))) %>%
filter(value) %>%
ggplot(aes(x = urban_pool, y = max_mean_abundance)) +
geom_boxplot() +
xlab('Threshold') +
ylab('Mean abundance across cities') +
labs(title = 'Mean Species Urban Abundance at each Threshold', subtitle='eBird Status & Trends abundance data') +
theme_bw() +
theme(legend.position = "none")
ggsave(filename(FIGURES_OUTPUT_DIR, 'thresholds_to_ebird_trends_and_status_abundance_data.jpg'))
comparison_data %>%
ggplot(aes(x = relative_abundance_proxy, y = sqrt(max_mean_abundance))) +
geom_point() +
xlab('Abundance Proxy') +
ylab('Mean abundance across cities (sqrt)') +
labs(title = 'Abundance proxy vs eBird relative abundance estimate', subtitle='eBird Status & Trends abundance data') +
theme_bw() +
theme(legend.position = "none")
ggsave(filename(FIGURES_OUTPUT_DIR, 'abundance_proxy_to_ebird_trends_and_status_abundance_data.jpg'))
city_data
sum(city_data$total_city_checklists)
raw_data
columbidae_checklists = read_csv(filename(EBIRD_WORKING_OUTPUT_DIR, 'urban_columbidae.csv'))
columbidae_checklists
columbidae_checklists = read_csv(filename(EBIRD_WORKING_OUTPUT_DIR, 'urban_columbidae.csv'))
columbidae_checklists %>% filter(city_id %in% city_data$city_id) %>% select(checklist_id) %>% distinct() %>% count()
city_data
city_data
city_data %>% arrange(total_city_area_m2) %>% mutate(total_city_area_km2 = total_city_area_m2 / (1000 * 1000)) %>% dplyr::select(city_name, total_city_area_m2)
city_data %>% arrange(total_city_area_m2) %>% mutate(total_city_area_km2 = total_city_area_m2 / (1000 * 1000)) %>% dplyr::select(city_name, total_city_area_km2)
source('../env.R')
city_polygons = read_sf(filename(CITY_DATA_OUTPUT_DIR, 'city_selection.shp'))
resolve = read_resolve()
